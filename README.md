# html_downloader
### Структура
`lib/html_downloader.py` - основной класс, реализующий асинхронную загрузку web-страниц
`lib/logger_conf.py` - конфигурация логирования
`lib/tools.py` - модуль, реализующий вспомогательные функции
`main.py` - основной файл для запуска
`requirements.txt` - список обязательных библиотек, которые должны быть установлены
### Запуск
Скрипт работает с интерпретатором python>=3.6
Перед первым запуском необходимо установить необходимые библиотеки из файла requirements.txt:
`python3.x -m pip install -r requirements.txt`
Запуск: `python3.x main.py`
По умолчанию, скрипт запускается со следующими параметрами:
* имя файла со списком сайтов - sites.csv
* папка назначения для записи результатов - downloaded
* лимит одновременно открытых соединений - 100
* имя файла со списком прокси - proxies.txt
* таймаут ожидания получения данных от сайта - 15

Для подробной информации об опциях запуска: `python3.x main.py --help`
### Описание работы
После запуска формируется список сайтов, очередь прокси, список задач. Каждая задача выполняется в асинхронном режиме: запрос страницы сайта и сохранение результата в виде исходного кода страницы и очищенного текста в файлы *.html и *.txt соответственно.
Результат сохраняется в папку назначения, указанныую при запуске скрипта, по умолчанию - `downloaded`.
В случае возникновении ошибок при запросе (http_status_code 400..599, timeout и т.п.), помимо логирования, в отдельный файл (`bad_url.log`) заносится информация о url сайта, используемом прокси и причине возникновении ошибки.